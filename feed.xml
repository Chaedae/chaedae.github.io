<feed xmlns="http://www.w3.org/2005/Atom"> <id>https://chaedae.github.io/</id><title>ChaeDae</title><subtitle>Description</subtitle> <updated>2022-09-01T17:43:43+09:00</updated> <author> <name>chaedae</name> <uri>https://chaedae.github.io/</uri> </author><link rel="self" type="application/atom+xml" href="https://chaedae.github.io/feed.xml"/><link rel="alternate" type="text/html" hreflang="en-US" href="https://chaedae.github.io/"/> <generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator> <rights> © 2022 chaedae </rights> <icon>/assets/img/favicons/favicon.ico</icon> <logo>/assets/img/favicons/favicon-96x96.png</logo> <entry><title>운영 시 유용한 명령어 모음</title><link href="https://chaedae.github.io/posts/%EB%AA%85%EB%A0%B9%EC%96%B4-%EB%AA%A8%EC%9D%8C/" rel="alternate" type="text/html" title="운영 시 유용한 명령어 모음" /><published>2022-08-18T16:38:00+09:00</published> <updated>2022-08-18T16:38:00+09:00</updated> <id>https://chaedae.github.io/posts/%EB%AA%85%EB%A0%B9%EC%96%B4-%EB%AA%A8%EC%9D%8C/</id> <content src="https://chaedae.github.io/posts/%EB%AA%85%EB%A0%B9%EC%96%B4-%EB%AA%A8%EC%9D%8C/" /> <author> <name>chaedae</name> </author> <category term="ETC" /> <category term="팁" /> <summary> 서버 운영을 하면서 자주 쓰이거나 자주 까먹는 명령어를 정리해봤다. 계속해서 업데이트 할 예정이다. LINUX # 용량 확인 서버전체: df -h 특정폴더: du -sh /경로 iNode: df -i # 파일 분할 용량기준: split -b 100M original.dat new_file.dat 라인기준: split -l 100000 original.csv new_file.csv # 기간 지난 파일 삭제 find /경로 -mtime +100 -exec rm -rf {} \; (생성된지 100일 지난 파일 삭제) # 파일 내 특정 단어 찾기 1. grep -R "찾을단어" 2. find ./ -depth -exec grep '찾을단어' {} \; -print # 인코딩 확인 및 변경 확... </summary> </entry> <entry><title>Kafka 데이터 연동</title><link href="https://chaedae.github.io/posts/Kafka-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%88%98%EC%A7%91/" rel="alternate" type="text/html" title="Kafka 데이터 연동" /><published>2022-08-01T17:12:00+09:00</published> <updated>2022-08-01T17:12:00+09:00</updated> <id>https://chaedae.github.io/posts/Kafka-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%88%98%EC%A7%91/</id> <content src="https://chaedae.github.io/posts/Kafka-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%88%98%EC%A7%91/" /> <author> <name>chaedae</name> </author> <category term="Python" /> <category term="BigData" /> <summary> Python 으로 Kafka 데이터를 연동하는 프로젝트를 진행했다. 개발환경 서버에 설치되어 있는 파이썬이 구버전이었는데 버전을 올려서 하기가 어려운 상황이라 그냥 진행했다. Python: 2.7 Kafka-python: 2.0.2 Elasticsearch: 6.8.2 프로세스 프로세스는 심플하다. 데이터를 가져와서 가공한 후에 각각의 서버로 넣어주는 파이프 역할이었다. Kafka Data Poll -&amp;gt; 전처리 -&amp;gt; Kafka Producer 전송 Kafka Data Poll -&amp;gt; 전처리 -&amp;gt; ES 적재 2개의 프로세스를 실시간으로 처리해야 해서 Thread 2개를 사용했다. 전처리 속도가 크게 문제되지 않는 수준이라 Thread를 사용했지만, ... </summary> </entry> <entry><title>Python 토픽 모델링</title><link href="https://chaedae.github.io/posts/Python-%ED%86%A0%ED%94%BD%EB%AA%A8%EB%8D%B8%EB%A7%81/" rel="alternate" type="text/html" title="Python 토픽 모델링" /><published>2021-12-13T17:42:00+09:00</published> <updated>2021-12-13T17:42:00+09:00</updated> <id>https://chaedae.github.io/posts/Python-%ED%86%A0%ED%94%BD%EB%AA%A8%EB%8D%B8%EB%A7%81/</id> <content src="https://chaedae.github.io/posts/Python-%ED%86%A0%ED%94%BD%EB%AA%A8%EB%8D%B8%EB%A7%81/" /> <author> <name>chaedae</name> </author> <category term="Python" /> <category term="BigData" /> <summary> 파이썬의 Gensim 라이브러리를 이용해서 토픽을 추출하는 프로젝트를 진행했다. 처음으로 파이썬으로 개발을 진행한 프로젝트라 기록을 남겨둔다. 데이터 1. 상품 및 유형 데이터 (2x3) 2. 하루 치 상담 데이터 (상품 및 유형 정보 포함) 3. 중복제거 된 상담사 데이터 4. 한국 지역 및 장소,지명 데이터 위의 데이터로 각 상품 &amp;amp; 유형 별 상위 10개의 토픽을 뽑아야 했다. 라이브러리 - gensim : 자연어 처리 모듈 - mecab : 형태소 분석기 - pyhive : python &amp;lt;-&amp;gt; hive - pandas 프로세스 Hive Data Load -&amp;gt; 데이터 중복 제거 -&amp;gt; 불용어 처리 -&amp;gt; 단어사전 생성 -&amp;gt; LDA 토픽 ... </summary> </entry> <entry><title>Python PyHive</title><link href="https://chaedae.github.io/posts/Python-PyHive/" rel="alternate" type="text/html" title="Python PyHive" /><published>2021-12-01T17:42:00+09:00</published> <updated>2021-12-01T17:42:00+09:00</updated> <id>https://chaedae.github.io/posts/Python-PyHive/</id> <content src="https://chaedae.github.io/posts/Python-PyHive/" /> <author> <name>chaedae</name> </author> <category term="Python" /> <category term="Library" /> <summary> PyHive 파이썬에서 hive로 접속해서 쿼리를 할 수 있게 도와주는 라이브러리다. pyhive 라이브러리는 Kerberos 프로토콜을 이용해서 python &amp;lt;-&amp;gt; hive 통신을 하기 때문에, 이와 관련된 라이브러리를 설치해줘야 한다. 설치 pip install sasl (인증 및 데이터보안) pip install thrift (이기종 통신) pip install thrift-sasl pip install pyhive 사용 from pyhive import hive conn = hive.Connection(host='호스트명', port=포트번호, username='유저명', password='패스워드', database='데이터베이스명', auth='CUSTOM') cur ... </summary> </entry> <entry><title>RestAPI에 Swagger 적용하기</title><link href="https://chaedae.github.io/posts/Rest-API%EC%97%90-Swagger-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0/" rel="alternate" type="text/html" title="RestAPI에 Swagger 적용하기" /><published>2019-01-18T20:52:00+09:00</published> <updated>2021-04-02T17:24:37+09:00</updated> <id>https://chaedae.github.io/posts/Rest-API%EC%97%90-Swagger-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0/</id> <content src="https://chaedae.github.io/posts/Rest-API%EC%97%90-Swagger-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0/" /> <author> <name>chaedae</name> </author> <category term="Java" /> <category term="Spring" /> <summary> «Tistory 블로그에서 작성했던 글» 이전에 만든 Rest 연습 프로젝트에 Swagger2를 적용해보았다. Swagger 는 프로젝트에 정의되어 있는 URL 매핑 정보를 브라우저로 한눈에 볼 수 있게 해주는 자동화 라이브러리이다. 또한, Postman 처럼 URL 호출 테스트도 지원한다. 그럼 이제 Swagger 적용을 해보자. 라이브러리 추가 우선 Swagger Dependency를 추가한다. &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;io.springfox&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;springfox-swagger2&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;2.8.0&amp;lt;/versi... </summary> </entry> </feed>
